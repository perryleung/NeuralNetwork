1、线性函数：输出 = (常数 * 输入) + (也许另一常数)

2、输入达到阈值，神经元就激发

3、激活函数/S函数/sigmoid函数/逻辑函数 y = 1/(1+e^(-x))

4、第一层节点仅表示输入信号，输入节点不对输入值应用激活函数

5、矩阵乘法/点乘/内积，与叉乘有别

6、[weights] * [inputs(列)] = 下层某单个节点的输入 即 X = W * I，最终此单个节点的输出 O=sigmoid(X)

7、更新权重的一种思想是在所有造成误差的节点中平分误差；另一种思想是不平等分误差，为较大权重的连接分配更多的误差，因为这些连接造成的误差的贡献大

8、两次使用了权重：第一次是将信号从输入向前传播到输出；第二次是将误差从输出向后传播到网络

9、误差标记值 = 训练数据期望输出值 - 实际输出值

10、Error(hidden) = W(hidden_output)转置 * Error(output)

11、梯度下降法(Gradient descent)是求解函数最小值的一种很好的方法，可以容忍不完善的数据

12、避免出现坠入错误的山谷：改变步长或从其他地方进行

13、我们使用的误差函数一般是（目标值-实际值）的平方，原因是可以容易计算梯度下降的斜率；平滑连续没有间断也没有突然跳跃；越接近最小值梯度越小意味着超调的风险低

14、计算出误差函数相对于权重的斜率需要微积分：求Error对链接权重的偏微分，ERROR = (t-o)的平方，t是常数而o是变量，用链式法则

15、误差函数可看同文件夹路径下的图片，值得注意的是我们研究只对误差函数的斜率方向感兴趣，因此式子前方的常系数可以去掉

17、sigmoid(x)对x的求导是： sigmoid(x)(1-sigmoid(x))

16、误差函数细节：第一部分的（目标值-实际值）误差，现在变成了隐藏层节点中重组的向后传播误差，正如在前面所看到的那样称为ERROR；sigmoid部分可以保持不变，但是内部的求和表达式指的是前一层，因此求和的范围是所有由权重调节的进入隐藏层节点的输入；最后一部分是第一层节点的输出

17、新权重 = 旧权重 - 学习率 * 误差函数

18、pass是for循环的一次循环的终止处，也可以是定义一个函数的终止处，也可以是一个类的终止处，#的名字是哈希符号

19、绘制二维数字数组的一种方式是将它们视为二维平面，根据数组中单元格的值对单元格进行着色，导入图形绘制功能：
import matplotlib.pyplot
%matplotlib inline	#不要试图在独立的外部窗口中绘制图形
matplotlib.pyplot.imshow(a,interpolation="nearest")	#a是数组
a = numpy.zeros([3,2])
a[0,1] = 1
a[0,0] = 5
a[1,0] = 9
a[2,1] = 18
print(a)
%matplotlib inline
matplotlib.pyplot.imshow(a,interpolation="nearest")

20、概念：从类的定义中创建处实例，这些实例称为对象，类中的函数可以被称为是对象的方法

21、当第一次创建对象时，Python会调用这个名字为__init__()的函数

22、神经网络框架代码一般至少有三大部分：1是初始化函数，用来设定输入层节点、隐藏层节点和输出层节点；2是训练，学习给定训练集样本后，优化权重；3是查询，给定输入，从输出节点给出答案

23、numpy.random.rand(3,3)是生成一个三行三列的数组，数组元素是介于（0-1）之间

24、权重是神经网络固有部分，它不是一个了临时数据集，不会随着函数调用结束而消失，意味着权重必须是初始化的一部分，并且也可以使用其他函数(训练函数、查询函数等)来访问

25、前馈的矩阵的行是前一层中的节点个数，列是后一层中的节点个数

26、以下是一种以正态分布的方式初始化权重，中心值、标准方差、numpy数组的大小，常用
    self.wih = np.random.normal(0.0,pow(self.hnodes,-0.5),(self.hnodes,self.inodes))
    self.who = np.random.normal(0.0,pow(self.onodes,-0.5),(self.onodes,self.hnodes))
    以下是一种随机分布的方式初始化权重，普通
    self.wih = np.random.rand(self.hnodes,self.inodes)
    self.who = np.random.rand(self.onodes,self.hnodes)

27、lambda语法是固定的，简单来说，编程中提到的 lambda 表达式，通常是在需要一个函数，但是又不想费神去命名一个函数的场合下使用，也就是指匿名函数。这一用法跟所谓 λ 演算（题目说明里的维基链接）的关系，有点像原子弹和质能方程的关系，差别其实还是挺大的。举例子：
g = lambda x : x + 1
g(1)
输出： 2
可以这样认为,lambda作为一个表达式，定义了一个匿名函数，上例的代码x为入口参数，x+1为函数体，用函数来表示为：
def g(x):
   return x+1
g(1)

28、训练train()函数部分包括两个步骤，第一步是计算输出，第二步就是反向传播误差

29、在.cvs文件中，每一行代表一个图片，一行有785列，第一列是标签，标签的值代表了这张图片的实际数字，后面的784列是28*28个像素点的值

30、打开文件并获取其中的内容，一般是三行代码，如下：
data_file = open("./doc/xxx.csv","r")
data_list = data_file.readlines()
data_file.close()
值得注意的是，open和close是必要的，open的第一个是路径文件，第二个参数可选，'r'是只读，这样可以避免任何更改数据或删除数据的意外，在open()函数创建了此文件的一个文件句柄、一个引用，将这个句柄分配给命名为data_file的变量，进一步操作读取文件都将通过句柄完成。使用与文件句柄data_file相关的readlines()函数将文件中的所有行读入变量data_list中，这个变量是一个列表，这个列表的一项是文件中一行的字符串。readlines()会将整个文件读取到内存中，也存在另外的方法可以一次读取一行，然后对这行操作。最后是关闭文件，在用完文件资源后，关闭和清理文件，可以释放计算机用于保存文件的部分内存。

31、打印图片着色：
data_file = open('xxx.csv','r')
data_list = data_file.readlines()
data_file.close()
import numpy
import matplotlib.pyplot as plt
%matplotlib inline
all_values = data_list[0].split(',')  # 这里是分离第一个数字，也就是分离第一张图片
image_array = np.asfarray(all_values[1:]).reshape((28,28))
plt.imshow(image_array,cmap='Greys',interpolation='None')

32、numpy.asfarray()是一个numpy函数，这个函数将文本字符串转换成实数，并创建这些数字的数组，上述代码原因如下：这个文件是以文本的形式读取的，每一行或每一条记录依然是文本，所有要将文本字符串转换为数字，最后一项.reshape((28,28))可以确保数字列表每28个元素折返一次形成一个28*28的数字矩阵，

33、要求神经网络分类，分配正确的标签，共有10个标签，那么输出层要有10个输出节点，每个节点可以被激活，但也只能激活一个

34、使用epochs进行重复多次训练，如下：
epochs = 5
for e in range(epochs):
    # 训练内容
    pass
训练一次也称为一个世代，多次训练可以提供更多下坡机会，有助于在梯度下降过程中进行权重更新，但不能太多否则会过拟合，不过，在更多世代的情况下，减小学习率确实能够得到更好的性能

35、可以创建较小的PNG图片，将它们调整到28个像素×28个像素，这样就可以匹配曾经用过的来自MNIST数据集的图片：
import scipy.misc
img_array = scipy.misc.imread(image_file_name,flatten=True)
img_data = 255.0 - img_array.reshape(784)
img_data = (img_data/255.0*0.99)+0.01
读取数据的函数imread()可以针对常见的图片文件格式，如JPG和PNG，flatten=True是将图像变成简单的浮点数组，而如果图像是彩色的那么颜色值将被转换成所需要的灰度，reshape()的目的是将其28*28的方块数组转换成一串数值；通常0是黑色，255是白色，但是MNIST数据集使用相反的方式表示。

36、图像旋转方式，以下尝试+10度和-10度
inputs_plus10_img = scipy.ndimage.interpolation.rotate(scaled_input.reshape(28,28),10,cval=0.01,reshape=False)
inputs_minus10_img = scipy.ndimage.interpolation.rotate(scaled_input.reshape(28,28),-10,cval=0.01,reshape=False)
备注：原先的scaled_input数组被重新转变为28*28的数组，然后进行调整，reshape=False是避免程序将图像“压扁”，使得数组旋转后可以完全适合而且没有剪掉任何部分，在原始图像中，一些数组元素不存在，但是现在这些数组元素进入了视野，cval就是用来填充数组元素的值，由于我们要移动输入值范围，避免0作为神经网络的输入值，因此不使用0.0作为默认值而是用0.01作为默认值。









































